## 问题场景

假设我们有如下的workflow：

```
image
  │
  │            ┌───┐ 
  ├───────────>│0  │     ┌───┐
  │   ┌───┐    │ B ├────>│ C │
  └──>│ A ├───>│1  │     └───┘
      └───┘    └───┘
```

其中 A 是BPU计算密集的Module，并且计算量和图片的内容密切相关，不同的图片计算量差距较大； B 接受image输入以及A的结果输出作为输入，需要做一些CPU密集的处理；但总的来说处理代价比A小很多。

接下来，我们需要优化这个workflow：尽可能地提高资源利用率，降低处理延迟，提高吞吐量。

#### 并行化与乱序

这样，A 处理延迟可能会很大，造成整体workflow的瓶颈。所以可以考虑把 A 并行化：

```
image
  │
  │                            ┌───┐ 
  ├───────────────────────────>│0  │     ┌───┐
  │   ┌───┐       ┌───┐        │ B ├────>│ C │
  └──>│ D ├───┬──>│ Aa├───┬───>│1  │     └───┘
      └───┘   │   └───┘   │    └───┘
              │   ┌───┐   │    
              ├──>│ Ab├───┤    
              │   └───┘   │    
              │   ┌───┐   │    
              └──>│ Ac├───┘    
                  └───┘   
```

`Aa` `Ab` `Ac` 都是类型和`A`一样的三个实例；`D` 是一个新开发的负责分发的Module，其功能是可以在每一帧图像来的时候，以Round Robin的策略把图像轮流发给 `Aa`, `Ab`, `Ac`，以此达到充分利用BPU、消除瓶颈`A`的目的。

我们假设连续俩帧输入的图片数据为`i0`和`i1`。`i0`包含很多车辆；`i1`包含的车辆较少。那么当`i1`被Feed之后，处理`i0`的`Aa`还没处理完，workflow中的数据可能会是这样：
```
image
  │
  │                       i1,i0┌───┐ 
  ├───────────────────────────>│0  │     ┌───┐
  │   ┌───┐     i0┌───┐        │ B ├────>│ C │
  └──>│ D ├───┬──>│ Aa├───┬───>│1  │     └───┘
      └───┘   │   └───┘   │    └───┘
              │ i1┌───┐   │    
              ├──>│ Ab├───┤    
              │   └───┘   │    
              │   ┌───┐   │    
              └──>│ Ac├───┘    
                  └───┘   
```

如果`i0`处理完成的时间早于`i1`处理完成的时间，那么一切都不会有问题。但是如果出现`i0`的处理完成时间晚于`i1`，就会出现`B`的输入数据不匹配的情况：

```   
image
  │
  │                       i1,i0┌───┐ 
  ├───────────────────────────>│0  │     ┌───┐
  │   ┌───┐       ┌───┐   a0,a1│ B ├────>│ C │
  └──>│ D ├───┬──>│ Aa├───┬───>│1  │     └───┘
      └───┘   │   └───┘   │    └───┘
              │   ┌───┐   │    
              ├──>│ Ab├───┤    
              │   └───┘   │    
              │   ┌───┐   │    
              └──>│ Ac├───┘    
                  └───┘   
```
这样B后续的执行结果就不对了。

#### 解决方案：重排序

一个办法是在`B`之前，加入一个Module，对数据`a` 按照 image 的顺序重新排序：

```
image
  │
  │                                i1,i0┌───┐ 
  ├────────────────────────────────────>│0  │     ┌───┐
  │   ┌───┐       ┌───┐      ┌───┐ a1,a0│ B ├────>│ C │
  └──>│ D ├───┬──>│ Aa├───┬─>│ S ├─────>│1  │     └───┘
      └───┘   │   └───┘   │  └───┘      └───┘
              │   ┌───┐   │    
              ├──>│ Ab├───┤    
              │   └───┘   │    
              │   ┌───┐   │    
              └──>│ Ac├───┘    
                  └───┘   
```
其中`S`是用来排序的Module，他的作用是将其输入的数据按照image的id的大小进行排序，再依次输出。

这样可以避免在module `B`出输入数据对应错乱的问题。

#### 解决方案：数据按照Feed 同步

但是上面这样的话，`i1`这一帧的数据在A环节先处理完，却还是需要等待`i0`处理完才能走后续的流程，这样可能造成`B` `C`处不必要的空闲；如果`B`和`C`的业务逻辑本身并不要求输入是按照时间顺序的话，我们应该允许进一步优化，就需要允许`B`可以先处理 `i1`, `a1`这一组数据，再处理`i0`, `a0`这一组数据：

```

image                       先处理Forward(i1, a1)
  │                        /
  │                       i1,i0┌───┐ 
  ├───────────────────────────>│0  │     ┌───┐
  │   ┌───┐     i0┌───┐   a1   │ B ├────>│ C │
  └──>│ D ├───┬──>│ Aa├───┬───>│1  │     └───┘
      └───┘   │   └───┘   │    └───┘
              │   ┌───┐   │    
              ├──>│ Ab├───┤    
              │   └───┘   │    
              │   ┌───┐   │    
              └──>│ Ac├───┘    
                  └───┘   
```

所以，可以引入一种机制，来确保`B`可以在自己的InputSlot中，识别出属于同一次Feed产生的数据，在这个的基础上执行Forward。

还是以同步编程来比喻：实现一个Module就相当于实现一个子函数；整个Workflow就相当于实现了一个主函数；在Workflow里面使用Link将Module连接起来，就相当于在这个主函数里面，调用不同的子函数，一些子函数的输出是另一些子函数的输入，由此构成数据依赖。

那么不同次的Feed就相当于对Workflow这个主函数的不同次的调用。在同步编程模式下，每次调用一个函数，其不同子函数的输入/输出数据相当于是局部变量，是在每次调用的线程栈上；所以不同次调用显然不会互相影响。但是在hobotsdk这样的流式处理框架中，我们就需要机制，来让用户有能力把每次“调用Workflow”——也就是每次Feed所产生的数据区分开来。

## 修改建议

### Workflow增加接口：一次Feed一组数据；Feed增加参数：feed_id

增加接口：
```c++
void Feed(spRunContext run_context,
                    std::list<std::tuple<Module *,   // module
                      int,                           // forward_index
                      int,                           // input_slot_index
                      spMessage>>                    // message
                      feed_messages, 
                    int64 feed_id = -1);
```

当前的Feed方法都只支持单个数据的Feed；所以需要确保有一个接口可以代表对整个Workflow的一次调用，这次调用可以输入多个Message。同时，加入一个参数`feed_id`作为这次feed的唯一id，作为区分不同feed的数据的依据。同时，现有的Feed接口也追加`feed_id`作为参数，默认值-1代表可忽略的feed_id。

### Message增加字段：feed_id

Message增加一个字段`feed_id`。被`Feed`的message的`feed_id`就是这次Feed的`feed_id`；只要module做了相应的设置，那么以这些message为输入执行Forward，所产生的message，也会得到相同的`feed_id`。详见下文。


### Workflow增加接口：SetSyncOnFeed

增加接口：
```c++
void DefaultWorkflow::SetSyncOnFeed(Module *module,
                                   int forward_index,
                                   std:list<int> input_slots,
                                   bool order_by_feedid = false
);
```
指定某个module的输入需要按照feed来同步输入数据。

当针对某个module调用这个接口时，改变这个module的设置，产生两个影响：

* 这个Module的`input_slots`所指定的Input Slots的数据按照feed_id同步：只在feed_id相同的message之间，对Condition的Expression表达式求值，不同的feed_id各自求值；表达式过了就可以执行Forward了。如果有Input Slot不在`input_slots`指定的范围内，那么这个Input Slot作为一个整体，跟随每一个feed_id进行表达式求值。如果`preserve_order`为true，那么就按照调用Feed时`feed_id`的顺序，依次检查运行各个`feed_id`的数据。
* 这个Module的`input_slots`所指定的Input Slots带来的feed_id传递给输出：这个Module的Forward执行过程中调用`Return`所产生的message，会带上来自`input_slots`的message中的feed_id。如果有Input Slot不在`input_slots`指定的范围内，那么这个Input Slot的message带来的`feed_id`被忽略。

默认情况下，每个module的设置中，SyncOnFeed的input_slots为空，上述行为关闭。

